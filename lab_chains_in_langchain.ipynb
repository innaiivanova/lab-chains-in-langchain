{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52824b89-532a-4e54-87e9-1410813cd39e",
      "metadata": {
        "id": "52824b89-532a-4e54-87e9-1410813cd39e"
      },
      "source": [
        "# Lab | Chains in LangChain\n",
        "\n",
        "## Outline\n",
        "\n",
        "* LLMChain\n",
        "* Sequential Chains\n",
        "  * SimpleSequentialChain\n",
        "  * SequentialChain\n",
        "* Router Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "541eb2f1",
      "metadata": {
        "id": "541eb2f1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
      "metadata": {
        "tags": [],
        "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b84e441b",
      "metadata": {
        "tags": [],
        "id": "b84e441b"
      },
      "outputs": [],
      "source": [
        "#!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
      "metadata": {
        "tags": [],
        "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/data/Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b7a09c35",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b7a09c35",
        "outputId": "e5d5ac66-89e1-440f-974a-8b7cd7e0936b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Product                                             Review\n",
              "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
              "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
              "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
              "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
              "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec6d67a2-7fdd-4b3c-965b-077460dccf77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Queen Size Sheet Set</td>\n",
              "      <td>I ordered a king size set. My only criticism w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Waterproof Phone Pouch</td>\n",
              "      <td>I loved the waterproof sac, although the openi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luxury Air Mattress</td>\n",
              "      <td>This mattress had a small hole in the top of i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pillows Insert</td>\n",
              "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Milk Frother Handheld\\n</td>\n",
              "      <td>I loved this product. But they only seem to l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec6d67a2-7fdd-4b3c-965b-077460dccf77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec6d67a2-7fdd-4b3c-965b-077460dccf77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec6d67a2-7fdd-4b3c-965b-077460dccf77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2bd13d9a-a116-4d64-879d-d33d0472fa35\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2bd13d9a-a116-4d64-879d-d33d0472fa35')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2bd13d9a-a116-4d64-879d-d33d0472fa35 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Product\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Queen Size Sheet Set\",\n          \"Waterproof Phone Pouch\",\n          \"L'Or Espresso Caf\\u00e9\\u00a0\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"I ordered a king size set. My only criticism would be that I wish seller would offer the king size set with 4 pillowcases. I separately ordered a two pack of pillowcases so I could have a total of four. When I saw the two packages, it looked like the color did not exactly match. Customer service was excellent about sending me two more pillowcases so I would have four that matched. Excellent! For the cost of these sheets, I am satisfied with the characteristics and coolness of the sheets.\",\n          \"I loved the waterproof sac, although the opening was made of a hard plastic. I don\\u2019t know if that would break easily. But I couldn\\u2019t turn my phone on, once it was in the pouch.\",\n          \"Je trouve le go\\u00fbt m\\u00e9diocre. La mousse ne tient pas, c'est bizarre. J'ach\\u00e8te les m\\u00eames dans le commerce et le go\\u00fbt est bien meilleur...\\nVieux lot ou contrefa\\u00e7on !?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b940ce7c",
      "metadata": {
        "id": "b940ce7c"
      },
      "source": [
        "## LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "427e1119",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427e1119",
        "outputId": "9ca3cba4-1c73-415f-9996-7df463535d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.35)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e92dff22",
      "metadata": {
        "tags": [],
        "id": "e92dff22"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "# Retrieve the API key from Colab secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# Set it as an environment variable, which LangChain often uses by default\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "print(\"OpenAI API key loaded and set as environment variable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rk2hxJ0GvSL",
        "outputId": "655f238a-919d-4810-921d-e64c6c224b54"
      },
      "id": "1Rk2hxJ0GvSL",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key loaded and set as environment variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "943237a7",
      "metadata": {
        "id": "943237a7"
      },
      "outputs": [],
      "source": [
        "#Replace None by your own value and justify\n",
        "llm = ChatOpenAI(temperature=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Temperature to 0.5, to see what results will be delivered."
      ],
      "metadata": {
        "id": "rjTHoJvgE5YW"
      },
      "id": "rjTHoJvgE5YW"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "cdcdb42d",
      "metadata": {
        "id": "cdcdb42d"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template( \"Deliver a {product} description outline.\"\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d7abc20b",
      "metadata": {
        "id": "d7abc20b"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ad44d1fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "ad44d1fb",
        "outputId": "106cbe77-f64c-41b6-b94a-0813d8fe0068"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I. Introduction\\n- Briefly introduce the product: Pillows Insert\\n- Mention the purpose of the insert: to provide support and comfort for pillows\\n\\nII. Key Features\\n- Material: soft and durable fabric\\n- Filling: plush and supportive material\\n- Size options: available in various sizes to fit different pillow covers\\n- Hypoallergenic: suitable for individuals with allergies\\n- Easy to clean: machine washable for convenience\\n\\nIII. Benefits\\n- Enhances the comfort and support of pillows\\n- Extends the lifespan of pillows by providing additional padding\\n- Hypoallergenic material is safe for sensitive individuals\\n- Easy to maintain and keep clean\\n\\nIV. Usage\\n- Insert the pillow insert into a pillow cover for added comfort\\n- Can be used in various settings, such as bedrooms, living rooms, and guest rooms\\n- Ideal for use during sleep, relaxation, or decorative purposes\\n\\nV. Conclusion\\n- Summarize the key features and benefits of the Pillows Insert\\n- Encourage customers to consider purchasing the insert for an enhanced pillow experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "product = \"Pillows Insert\"\n",
        "chain.run(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat for Matress"
      ],
      "metadata": {
        "id": "fboXKmbTHm7A"
      },
      "id": "fboXKmbTHm7A"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template( \"Deliver a {product} description outline.\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "fIUUxcp-HoYv"
      },
      "id": "fIUUxcp-HoYv",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "rpR7EK6zHruD"
      },
      "id": "rpR7EK6zHruD",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product = \"Luxury Air Mattress\"\n",
        "chain.run(product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "8pIzvM3FHuPf",
        "outputId": "271bb72b-458d-4661-ef22-b3a73048f955"
      },
      "id": "8pIzvM3FHuPf",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I. Introduction\\n- Introduce the luxury air mattress and its features\\n- Highlight the benefits of using a luxury air mattress\\n\\nII. Material and Construction\\n- Discuss the high-quality materials used in the construction of the luxury air mattress\\n- Detail the construction process and how it contributes to the overall comfort and durability of the mattress\\n\\nIII. Comfort and Support\\n- Explain how the luxury air mattress provides superior comfort and support compared to traditional air mattresses\\n- Describe the unique features that enhance the sleeping experience, such as adjustable firmness levels and plush pillow tops\\n\\nIV. Design and Aesthetics\\n- Discuss the sleek and stylish design of the luxury air mattress\\n- Highlight any special design elements that set it apart from other air mattresses on the market\\n\\nV. Additional Features\\n- Mention any additional features that make the luxury air mattress stand out, such as built-in pumps, remote controls, or storage compartments\\n- Explain how these features enhance the overall user experience\\n\\nVI. Warranty and Customer Support\\n- Detail the warranty coverage and customer support options available for the luxury air mattress\\n- Highlight any guarantees or assurances provided by the manufacturer\\n\\nVII. Conclusion\\n- Summarize the key points of the luxury air mattress description\\n- Encourage readers to consider investing in a luxury air mattress for a more comfortable and restful sleep experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b03469",
      "metadata": {
        "id": "69b03469"
      },
      "source": [
        "## SimpleSequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "febee243",
      "metadata": {
        "id": "febee243"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2f31aa8a",
      "metadata": {
        "id": "2f31aa8a"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    #Repeat the initial query or create a new query that would feed into the second prompt\n",
        "    \"Deliver a {product} description outline.\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3f5d5b76",
      "metadata": {
        "id": "3f5d5b76"
      },
      "outputs": [],
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Deliver a brief product blog post based on the product outline:\\n\\n{product_outline}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6c1eb2c4",
      "metadata": {
        "id": "6c1eb2c4"
      },
      "outputs": [],
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "78458efe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "78458efe",
        "outputId": "d1e57f62-c28f-4fb1-8c39-307c5db9c381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mI. Introduction \n",
            "    A. Explanation of the product\n",
            "    B. Benefits of using a luxury air mattress \n",
            "\n",
            "II. Features \n",
            "    A. High-quality materials \n",
            "    B. Comfortable design \n",
            "    C. Adjustable firmness \n",
            "    D. Built-in pump \n",
            "    E. Extra thick for added support \n",
            "\n",
            "III. Benefits \n",
            "    A. Promotes better sleep \n",
            "    B. Easy to set up and inflate \n",
            "    C. Portable and convenient for travel \n",
            "    D. Durable and long-lasting \n",
            "    E. Ideal for guests or camping trips \n",
            "\n",
            "IV. Price and Availability \n",
            "    A. Price range \n",
            "    B. Where to purchase \n",
            "    C. Warranty information \n",
            "\n",
            "V. Conclusion \n",
            "    A. Recap of key points \n",
            "    B. Encouragement to invest in a luxury air mattress for a better night's sleep.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mIntroducing our high-quality luxury air mattress - the ultimate solution for a good night's sleep. Made with top-notch materials and a comfortable design, this air mattress offers adjustable firmness and extra thickness for added support. The built-in pump makes inflating a breeze, and its durability ensures long-lasting use.\n",
            "\n",
            "Using a luxury air mattress promotes better sleep, is easy to set up and inflate, and is portable for travel. Whether you have guests staying over or are going on a camping trip, this mattress is the perfect choice.\n",
            "\n",
            "With a reasonable price range and availability at various retailers, investing in a luxury air mattress is a smart choice for anyone looking for a comfortable and convenient bedding solution. Plus, with warranty information included, you can rest assured knowing your investment is protected.\n",
            "\n",
            "Don't compromise on your sleep - upgrade to a luxury air mattress today and experience the difference in quality and comfort.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Introducing our high-quality luxury air mattress - the ultimate solution for a good night's sleep. Made with top-notch materials and a comfortable design, this air mattress offers adjustable firmness and extra thickness for added support. The built-in pump makes inflating a breeze, and its durability ensures long-lasting use.\\n\\nUsing a luxury air mattress promotes better sleep, is easy to set up and inflate, and is portable for travel. Whether you have guests staying over or are going on a camping trip, this mattress is the perfect choice.\\n\\nWith a reasonable price range and availability at various retailers, investing in a luxury air mattress is a smart choice for anyone looking for a comfortable and convenient bedding solution. Plus, with warranty information included, you can rest assured knowing your investment is protected.\\n\\nDon't compromise on your sleep - upgrade to a luxury air mattress today and experience the difference in quality and comfort.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "overall_simple_chain.run(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
      "metadata": {
        "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f"
      },
      "source": [
        "**Repeat the above twice for different products**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating for Pillows Insert"
      ],
      "metadata": {
        "id": "b9X0uPEmJxmw"
      },
      "id": "b9X0uPEmJxmw"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "E2qG95f_J3bM"
      },
      "id": "E2qG95f_J3bM",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "product = \"Pillows Insert\"\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    #Repeat the initial query or create a new query that would feed into the second prompt\n",
        "    \"Deliver a {product} description outline.\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
      ],
      "metadata": {
        "id": "TvCovTjzJ3TI"
      },
      "id": "TvCovTjzJ3TI",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Deliver a brief product blog post based on the product outline:\\n\\n{product_outline}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "qVempICuJ3KZ"
      },
      "id": "qVempICuJ3KZ",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ],
      "metadata": {
        "id": "K4t9NhlFJ3Bp"
      },
      "id": "K4t9NhlFJ3Bp",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain.run(product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "yMH7ESRoJ247",
        "outputId": "a0c76351-227e-4aa5-cb64-dda74c425c63"
      },
      "id": "yMH7ESRoJ247",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mI. Introduction\n",
            "- Briefly introduce the product: Pillow Insert\n",
            "- Mention the purpose of the insert: to provide support and fluffiness to pillows\n",
            "\n",
            "II. Material and Construction\n",
            "- Describe the material used for the insert (e.g. polyester, down alternative)\n",
            "- Explain the construction of the insert (e.g. sewn seams, double stitching)\n",
            "\n",
            "III. Size and Shape Options\n",
            "- List the available sizes and shapes of the pillow insert (e.g. square, rectangle, round)\n",
            "- Mention any custom sizing options available\n",
            "\n",
            "IV. Features\n",
            "- Outline any additional features of the insert (e.g. hypoallergenic, machine washable, fade resistant)\n",
            "\n",
            "V. Benefits\n",
            "- Explain the benefits of using a pillow insert (e.g. prolonging the life of the pillow cover, providing comfort and support)\n",
            "- Mention how the insert can enhance the look and feel of a pillow\n",
            "\n",
            "VI. Care Instructions\n",
            "- Provide care instructions for the insert (e.g. machine wash on gentle cycle, tumble dry low)\n",
            "- Offer tips for maintaining the insert's shape and fluffiness\n",
            "\n",
            "VII. Conclusion\n",
            "- Summarize the key points about the pillow insert\n",
            "- Encourage customers to consider purchasing the insert for their pillows for added comfort and support.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mIntroducing our Pillow Insert, designed to provide the perfect combination of support and fluffiness to your pillows. Made with high-quality polyester and constructed with durable sewn seams and double stitching, our inserts are built to last.\n",
            "\n",
            "Available in a variety of sizes and shapes, including square, rectangle, and round, with custom sizing options available upon request. Our pillow inserts also come with additional features such as hypoallergenic material, machine washability, and fade resistance.\n",
            "\n",
            "By using our pillow insert, you can prolong the life of your pillow cover, while enjoying enhanced comfort and support. Maintain the insert's shape and fluffiness by following our care instructions, which include machine washing on a gentle cycle and tumble drying on low heat.\n",
            "\n",
            "In conclusion, our Pillow Insert is the perfect addition to your pillows for added comfort and support. Elevate the look and feel of your pillows today with our high-quality insert.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Introducing our Pillow Insert, designed to provide the perfect combination of support and fluffiness to your pillows. Made with high-quality polyester and constructed with durable sewn seams and double stitching, our inserts are built to last.\\n\\nAvailable in a variety of sizes and shapes, including square, rectangle, and round, with custom sizing options available upon request. Our pillow inserts also come with additional features such as hypoallergenic material, machine washability, and fade resistance.\\n\\nBy using our pillow insert, you can prolong the life of your pillow cover, while enjoying enhanced comfort and support. Maintain the insert's shape and fluffiness by following our care instructions, which include machine washing on a gentle cycle and tumble drying on low heat.\\n\\nIn conclusion, our Pillow Insert is the perfect addition to your pillows for added comfort and support. Elevate the look and feel of your pillows today with our high-quality insert.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating for Waterproof Phone Pouch"
      ],
      "metadata": {
        "id": "cy2yzFtQKvbA"
      },
      "id": "cy2yzFtQKvbA"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "CG3bq4NnKz38"
      },
      "id": "CG3bq4NnKz38",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "product = \"Waterproof Phone Pouch\"\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    #Repeat the initial query or create a new query that would feed into the second prompt\n",
        "    \"Deliver a {product} description outline.\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
      ],
      "metadata": {
        "id": "8kAUdir3Kzua"
      },
      "id": "8kAUdir3Kzua",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Deliver a brief product blog post based on the product outline:\\n\\n{product_outline}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "r8SNtPijKzlW"
      },
      "id": "r8SNtPijKzlW",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ],
      "metadata": {
        "id": "sdoy_D96Kzbr"
      },
      "id": "sdoy_D96Kzbr",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain.run(product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "9uHSuUJRKzR5",
        "outputId": "7bb12f0b-1a7e-4662-8386-a3f42383cdea"
      },
      "id": "9uHSuUJRKzR5",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mI. Introduction\n",
            "    A. Brief overview of the product\n",
            "    B. Importance of protecting phones from water damage\n",
            "\n",
            "II. Features\n",
            "    A. Waterproof design to keep phone safe in water\n",
            "    B. Transparent cover for easy touchscreen access\n",
            "    C. Adjustable strap for comfortable carrying\n",
            "    D. Compatible with most smartphones\n",
            "\n",
            "III. Benefits\n",
            "    A. Keep phone safe at the beach, pool, or in the rain\n",
            "    B. Take underwater photos and videos\n",
            "    C. Easily access phone without taking it out of the pouch\n",
            "    D. Lightweight and portable for on-the-go use\n",
            "\n",
            "IV. How to Use\n",
            "    A. Open the pouch and insert phone\n",
            "    B. Seal the pouch securely\n",
            "    C. Adjust the strap for comfortable wearing\n",
            "    D. Use phone as normal through the transparent cover\n",
            "\n",
            "V. Conclusion\n",
            "    A. Recap of benefits and features\n",
            "    B. Encourage customers to purchase the waterproof phone pouch for peace of mind and convenience.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mIntroducing our new Waterproof Phone Pouch! \n",
            "\n",
            "In today's world, our phones are an essential part of our daily lives. From staying connected to capturing memories, we rely on our smartphones for so much. That's why it's crucial to protect them from water damage, especially when we're out and about in wet environments.\n",
            "\n",
            "Our Waterproof Phone Pouch is designed to keep your phone safe and dry in water. With a transparent cover that allows for easy touchscreen access, an adjustable strap for comfortable carrying, and compatibility with most smartphones, this pouch is a must-have accessory for anyone who enjoys spending time at the beach, pool, or in the rain.\n",
            "\n",
            "Not only does our Waterproof Phone Pouch protect your phone from water damage, but it also allows you to take underwater photos and videos, easily access your phone without taking it out of the pouch, and stay lightweight and portable for on-the-go use.\n",
            "\n",
            "Using the pouch is simple - just open the pouch, insert your phone, seal it securely, adjust the strap for comfortable wearing, and use your phone as normal through the transparent cover.\n",
            "\n",
            "Don't let water ruin your phone - invest in our Waterproof Phone Pouch for peace of mind and convenience. Order yours today!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Introducing our new Waterproof Phone Pouch! \\n\\nIn today's world, our phones are an essential part of our daily lives. From staying connected to capturing memories, we rely on our smartphones for so much. That's why it's crucial to protect them from water damage, especially when we're out and about in wet environments.\\n\\nOur Waterproof Phone Pouch is designed to keep your phone safe and dry in water. With a transparent cover that allows for easy touchscreen access, an adjustable strap for comfortable carrying, and compatibility with most smartphones, this pouch is a must-have accessory for anyone who enjoys spending time at the beach, pool, or in the rain.\\n\\nNot only does our Waterproof Phone Pouch protect your phone from water damage, but it also allows you to take underwater photos and videos, easily access your phone without taking it out of the pouch, and stay lightweight and portable for on-the-go use.\\n\\nUsing the pouch is simple - just open the pouch, insert your phone, seal it securely, adjust the strap for comfortable wearing, and use your phone as normal through the transparent cover.\\n\\nDon't let water ruin your phone - invest in our Waterproof Phone Pouch for peace of mind and convenience. Order yours today!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b5ce18c",
      "metadata": {
        "id": "7b5ce18c"
      },
      "source": [
        "## SequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "4c129ef6",
      "metadata": {
        "id": "4c129ef6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "016187ac",
      "metadata": {
        "id": "016187ac"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "  \"Translate the following review to Spanish: {review}\"\n",
        ")\n",
        "\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"spanish_review\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eab909f",
        "outputId": "f0b4ddf0-e7db-4959-fbba-0cf154c1171d"
      },
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ],
      "id": "3eab909f",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'spanish_review': 'Original: \"This restaurant has amazing food and great service. I highly recommend it to anyone looking for a delicious meal.\"\\n\\nTranslation: \"Este restaurante tiene comida increÃ­ble y un excelente servicio. Lo recomiendo altamente a cualquiera que busque una comida deliciosa.\"',\n",
              " 'spanish_summary': \"The review praises the product for its high-quality construction, powerful performance, and user-friendly features. The reviewer also notes that the product's price may be on the higher side compared to other similar products, but it is worth the investment for its durability and reliability. Overall, the reviewer highly recommends the product for anyone looking for a top-performing and long-lasting option.\",\n",
              " 'english_summary': 'The summary is not provided.',\n",
              " 'both_summaries': \"The summary is not provided.\\n\\nThe review praises the product for its high-quality construction, powerful performance, and user-friendly features. The reviewer also notes that the product's price may be on the higher side compared to other similar products, but it is worth the investment for its durability and reliability. Overall, the reviewer highly recommends the product for anyone looking for a top-performing and long-lasting option.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "0fb0730e",
      "metadata": {
        "id": "0fb0730e"
      },
      "outputs": [],
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following Spanish review: {spanish_review}\"\n",
        ")\n",
        "\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"spanish_summary\"\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "6accf92d",
      "metadata": {
        "id": "6accf92d"
      },
      "outputs": [],
      "source": [
        "# prompt template 3: translate to english or other language\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following Spanish summary to English: {spanish_summary}\"\n",
        ")\n",
        "# chain 3: input= Review and output= language\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"english_summary\"\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "c7a46121",
      "metadata": {
        "id": "c7a46121"
      },
      "outputs": [],
      "source": [
        "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Append the {spanish_summary} to the {english_summary}, so that both summaries are displayed one after the other.\"\n",
        ")\n",
        "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
        "                      output_key=\"both_summaries\"\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "89603117",
      "metadata": {
        "id": "89603117"
      },
      "outputs": [],
      "source": [
        "# overall_chain: input= Review\n",
        "# and output= English_Review,summary, followup_message\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
        "    input_variables=[\"review\"],\n",
        "    output_variables=[\"spanish_review\", \"spanish_summary\",\"english_summary\",\"both_summaries\"],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "51b04f45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51b04f45",
        "outputId": "7fc4d93b-3a28-4be2-96fb-f5da9e8a6bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'spanish_review': 'Encuentro el sabor mediocre. La espuma no se sostiene, es extraÃ±o. Compro los mismos en el comercio y el sabor es mucho mejor... Â¿Lote viejo o falsificaciÃ³n?',\n",
              " 'spanish_summary': 'El escritor califica el sabor como mediocre y menciona que la espuma no se mantiene. Sospecha que el producto podrÃ­a ser un lote viejo o una falsificaciÃ³n, ya que ha comprado el mismo producto en el comercio y ha tenido una mejor experiencia con el sabor.',\n",
              " 'english_summary': 'The writer rates the taste as mediocre and mentions that the foam does not hold up. He suspects that the product could be an old batch or a counterfeit, as he has bought the same product in stores and has had a better experience with the taste.',\n",
              " 'both_summaries': 'The writer rates the taste as mediocre and mentions that the foam does not hold up. He suspects that the product could be an old batch or a counterfeit, as he has bought the same product in stores and has had a better experience with the taste.\\n\\nEl escritor califica el sabor como mediocre y menciona que la espuma no se mantiene. Sospecha que el producto podrÃ­a ser un lote viejo o una falsificaciÃ³n, ya que ha comprado el mismo producto en el comercio y ha tenido una mejor experiencia con el sabor.'}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
      "metadata": {
        "id": "3187cf07-458a-4226-bec7-3dec7ee47af2"
      },
      "source": [
        "**Repeat the above twice for different products or reviews**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating for having Reviews in Chineese"
      ],
      "metadata": {
        "id": "1v6YrxWTPWqx"
      },
      "id": "1v6YrxWTPWqx"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "T4hukOogPZKL"
      },
      "id": "T4hukOogPZKL",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "  \"Translate the following review to Chineese: {review}\"\n",
        ")\n",
        "\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"chineese_review\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "MXyRfbj6PZEd"
      },
      "id": "MXyRfbj6PZEd",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33GKZoE-PY-E",
        "outputId": "f07a7931-a895-48c4-f9fe-8aba91096ccd"
      },
      "id": "33GKZoE-PY-E",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'chineese_review': 'æè§å¾å³éå¾ä¸è¬ãæ³¡æ²«ä¸å¤æä¹ï¼å¾å¥æªãæå¨ååºä¹°çåæ ·äº§åå³éå¥½å¤äº...æ¯è¿æçè¿æ¯åè´§!?',\n",
              " 'chineese_summary': 'The reviewer feels that the taste is average and the foam is not long-lasting, which is strange. They believe that the same product bought at a store tastes much better. They question whether the product is expired or counterfeit.',\n",
              " 'english_summary': \"The reviewer thinks that the flavor is average and the foam doesn't last long, which is odd. They think that the same product purchased at a store tastes much better. They wonder if the product is expired or fake.\",\n",
              " 'both_summaries': \"The reviewer thinks that the flavor is average and the foam doesn't last long, which is odd. They think that the same product purchased at a store tastes much better. They wonder if the product is expired or fake.\\n\\nThe reviewer feels that the taste is average and the foam is not long-lasting, which is strange. They believe that the same product bought at a store tastes much better. They question whether the product is expired or counterfeit.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following Chinese review: {chineese_review}\"\n",
        ")\n",
        "\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"chineese_summary\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "EXUWFSdnPY4P"
      },
      "id": "EXUWFSdnPY4P",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: translate to english or other language\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following Chineese summary to English: {chineese_summary}\"\n",
        ")\n",
        "# chain 3: input= Review and output= language\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"english_summary\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "XkTEi-PvPYxF"
      },
      "id": "XkTEi-PvPYxF",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Append the {chineese_summary} to the {english_summary}, so that both summaries are displayed one after the other.\"\n",
        ")\n",
        "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
        "                      output_key=\"both_summaries\"\n",
        "                     )"
      ],
      "metadata": {
        "id": "nWcmWlb5PYpS"
      },
      "id": "nWcmWlb5PYpS",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_chain: input= Review\n",
        "# and output= English_Review,summary, followup_message\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
        "    input_variables=[\"review\"],\n",
        "    output_variables=[\"chineese_review\", \"chineese_summary\",\"english_summary\",\"both_summaries\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "TuZ8pbyTPYgQ"
      },
      "id": "TuZ8pbyTPYgQ",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vWxNkjBPYMr",
        "outputId": "874e634a-20c8-4103-aa34-146f3fdbaba3"
      },
      "id": "0vWxNkjBPYMr",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'chineese_review': 'æè§å¾å³éå¾å·®ãæ³¡æ²«ä¸æä¹ï¼å¾å¥æªãæå¨ååºéä¹°çä¸æ ·çå£æå¥½å¤äº... æ¯æ§è´§è¿æ¯ååè´§ï¼',\n",
              " 'chineese_summary': \"The reviewer feels that the taste is very poor, the foam doesn't last long and is strange. They purchased the same product from a store and found the taste much better. They suspect if it is old or counterfeit goods.\",\n",
              " 'english_summary': 'The reviewer believes that the flavor is very bad, the foam dissipates quickly, and it tastes strange. They bought the same product from a store and found the taste to be much better. They suspect that it might be old or counterfeit goods.',\n",
              " 'both_summaries': \"The reviewer feels that the taste is very poor, the foam doesn't last long and is strange. They purchased the same product from a store and found the taste much better. They suspect if it is old or counterfeit goods.\\n\\nThe reviewer believes that the flavor is very bad, the foam dissipates quickly, and it tastes strange. They bought the same product from a store and found the taste to be much better. They suspect that it might be old or counterfeit goods.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately translation didn't work out so well."
      ],
      "metadata": {
        "id": "5SpN-ALyUE8g"
      },
      "id": "5SpN-ALyUE8g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating for different products - Pillows Insert and Queen Size Sheet Set"
      ],
      "metadata": {
        "id": "D2JG2AxzZSBr"
      },
      "id": "D2JG2AxzZSBr"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "9dzsstElZYzy"
      },
      "id": "9dzsstElZYzy",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.9)\n",
        "\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "  \"Translate the following review to English: {review}\"\n",
        ")\n",
        "\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt,\n",
        "                     output_key=\"english_review\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "A9D6JsOwZYuf"
      },
      "id": "A9D6JsOwZYuf",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD_I8vIlZYox",
        "outputId": "f18ae6a3-992d-406d-d753-c6c7729aa97c"
      },
      "id": "fD_I8vIlZYox",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'chineese_review': 'æè§å¾å³éå¾å·®ã æ³¡æ²«ä¸æä¹ï¼å¾å¥æªã æå¨ååºä¹°çä¸æ ·çå³éæ´å¥½...æ¯æ§æ¹æ¬¡è¿æ¯åè´§ï¼ï¼',\n",
              " 'chineese_summary': 'The reviewer feels that the taste is poor and the foam is not long-lasting, which is strange. They believe that the same flavor they bought at the store is better, leading them to question if the product is from an old batch or if it is counterfeit.',\n",
              " 'english_summary': 'Reviewer believes that the taste is not good and the foam does not last long, which is strange. They think that the same flavor they bought from the store is better, making them wonder if the product is from an old batch or if it is counterfeit.',\n",
              " 'both_summaries': 'The reviewer feels that the taste is poor and the foam is not long-lasting, which is strange. They believe that the same flavor they bought at the store is better, leading them to question if the product is from an old batch or if it is counterfeit.\\n\\nReviewer believes that the taste is not good and the foam does not last long, which is strange. They think that the same flavor they bought from the store is better, making them wonder if the product is from an old batch or if it is counterfeit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following English reviews for Pillows Insert: {english_review}\"\n",
        ")\n",
        "\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt,\n",
        "                     output_key=\"pillow_english_summary\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "O87h1ZnFZYjI"
      },
      "id": "O87h1ZnFZYjI",
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: translate to english or other language\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the following English reviews for Queen Size Sheet Set: {pillow_english_summary}\"\n",
        ")\n",
        "# chain 3: input= Review and output= language\n",
        "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
        "                       output_key=\"sheet_english_summary\"\n",
        "                      )"
      ],
      "metadata": {
        "id": "qyz-zOOmZYdI"
      },
      "id": "qyz-zOOmZYdI",
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "        \"Append the {sheet_english_summary} to the {pillow_english_summary}, so that both summaries are displayed one after the other.\"\n",
        ")\n",
        "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
        "                      output_key=\"both_summaries\"\n",
        "                     )"
      ],
      "metadata": {
        "id": "zRMYym1CZYXJ"
      },
      "id": "zRMYym1CZYXJ",
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_chain: input= Review\n",
        "# and output= English_Review,summary, followup_message\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
        "    input_variables=[\"review\"],\n",
        "    output_variables=[\"english_review\", \"pillow_english_summary\",\"sheet_english_summary\",\"both_summaries\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "tSoHvWUKZYPe"
      },
      "id": "tSoHvWUKZYPe",
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = df.Review[5]\n",
        "overall_chain(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqDj4AEWZYHJ",
        "outputId": "3da53fbf-2863-478a-a642-5b90ac5d0823"
      },
      "id": "BqDj4AEWZYHJ",
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
              " 'english_review': \"I find the taste mediocre. The foam doesn't last, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
              " 'pillow_english_summary': \"The reviewer finds the pillow insert to have a mediocre taste and notes that the foam doesn't last. They suggest that the product may be an old batch or counterfeit as they have bought the same pillows in stores with better quality.\",\n",
              " 'sheet_english_summary': 'The reviewer is dissatisfied with the Queen Size Sheet Set, particularly noting a mediocre taste in the pillow insert and the foam not lasting. They suspect the product may be old or counterfeit, as they have bought the same pillows in stores with better quality.',\n",
              " 'both_summaries': \"The reviewer finds the pillow insert to have a mediocre taste and notes that the foam doesn't last. They suggest that the product may be an old batch or counterfeit as they have bought the same pillows in stores with better quality.\\n\\nThe reviewer is dissatisfied with the Queen Size Sheet Set, particularly noting a mediocre taste in the pillow insert and the foam not lasting. They suspect the product may be old or counterfeit, as they have bought the same pillows in stores with better quality.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3041ea4c",
      "metadata": {
        "id": "3041ea4c"
      },
      "source": [
        "## Router Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "ade83f4f",
      "metadata": {
        "id": "ade83f4f"
      },
      "outputs": [],
      "source": [
        "physics_template = \"\"\"You are a very smart physics professor. \\\n",
        "You are great at answering questions about physics in a concise\\\n",
        "and easy to understand manner. \\\n",
        "When you don't know the answer to a question you admit\\\n",
        "that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "math_template = \"\"\"You are a very good mathematician. \\\n",
        "You are great at answering math questions. \\\n",
        "You are so good because you are able to break down \\\n",
        "hard problems into their component parts,\n",
        "answer the component parts, and then put them together\\\n",
        "to answer the broader question.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "history_template = \"\"\"You are a very good historian. \\\n",
        "You have an excellent knowledge of and understanding of people,\\\n",
        "events and contexts from a range of historical periods. \\\n",
        "You have the ability to think, reflect, debate, discuss and \\\n",
        "evaluate the past. You have a respect for historical evidence\\\n",
        "and the ability to make use of it to support your explanations \\\n",
        "and judgements.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
        "You have a passion for creativity, collaboration,\\\n",
        "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
        "understanding of theories and algorithms, and excellent communication \\\n",
        "skills. You are great at answering coding questions. \\\n",
        "You are so good because you know how to solve a problem by \\\n",
        "describing the solution in imperative steps \\\n",
        "that a machine can easily interpret and you know how to \\\n",
        "choose a solution that has a good balance between \\\n",
        "time complexity and space complexity.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "biology_template = \"\"\"You are an excellent biologist. \\\n",
        "You have a deep understanding of living organisms, \\\n",
        "from the molecular and cellular level to entire ecosystems. \\\n",
        "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
        "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
        "You can clearly communicate how life functions and adapts, \\\n",
        "and you make connections between different biological concepts \\\n",
        "to answer challenging questions.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "5f590e9f",
      "metadata": {
        "id": "5f590e9f"
      },
      "outputs": [],
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"physics\",\n",
        "        \"description\": \"Good for answering questions about physics\",\n",
        "        \"prompt_template\": physics_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"math\",\n",
        "        \"description\": \"Good for answering math questions\",\n",
        "        \"prompt_template\": math_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"History\",\n",
        "        \"description\": \"Good for answering history questions\",\n",
        "        \"prompt_template\": history_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"computer science\",\n",
        "        \"description\": \"Good for answering computer science questions\",\n",
        "        \"prompt_template\": computerscience_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"biology\",\n",
        "        \"description\": \"Good for answering biology questions\",\n",
        "        \"prompt_template\": biology_template\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "31b06fc8",
      "metadata": {
        "id": "31b06fc8"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "f3f50bcc",
      "metadata": {
        "id": "f3f50bcc"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "8eefec24",
      "metadata": {
        "id": "8eefec24"
      },
      "outputs": [],
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "9f98018a",
      "metadata": {
        "id": "9f98018a"
      },
      "outputs": [],
      "source": [
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "11b2e2ba",
      "metadata": {
        "id": "11b2e2ba"
      },
      "outputs": [],
      "source": [
        "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
        "language model select the model prompt best suited for the input. \\\n",
        "You will be given the names of the available prompts and a \\\n",
        "description of what the prompt is best suited for. \\\n",
        "You may also revise the original input if you think that revising\\\n",
        "it will ultimately lead to a better response from the language model.\n",
        "\n",
        "<< FORMATTING >>\n",
        "Return a markdown code snippet with a JSON object formatted to look like:\n",
        "```json\n",
        "{{{{\n",
        "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
        "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
        "}}}}\n",
        "```\n",
        "\n",
        "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
        "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
        "well suited for any of the candidate prompts.\n",
        "REMEMBER: \"next_inputs\" can just be the original input \\\n",
        "if you don't think any modifications are needed.\n",
        "\n",
        "<< CANDIDATE PROMPTS >>\n",
        "{destinations}\n",
        "\n",
        "<< INPUT >>\n",
        "{{input}}\n",
        "\n",
        "<< OUTPUT (remember to include the ```json)>>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "1387109d",
      "metadata": {
        "id": "1387109d"
      },
      "outputs": [],
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "2fb7d560",
      "metadata": {
        "id": "2fb7d560"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(router_chain=router_chain,\n",
        "                         destination_chains=destination_chains,\n",
        "                         default_chain=default_chain, verbose=True\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "d86b2131",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "d86b2131",
        "outputId": "5a0a1156-6894-4be2-dca6-df6aa994b178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "physics: {'input': 'What is black body radiation?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation and emits radiation at all frequencies. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding concepts such as thermal radiation and the behavior of objects at different temperatures.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "chain.run(\"What is black body radiation?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "3b717379",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "3b717379",
        "outputId": "46b5add2-c841-4769-dc9f-424abc9d58b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "math: {'input': 'what is 2 + 2'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 + 2 is equal to 4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "chain.run(\"what is 2 + 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "29e5be01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "29e5be01",
        "outputId": "bc87d097-1d16-4fa5-f7c2-960a6ca66e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the proteins that make up our cells and tissues. \\n\\nHaving DNA in every cell ensures that each cell has the necessary genetic information to carry out its specific functions and to replicate itself accurately during cell division. This ensures that the genetic information is passed on to the next generation of cells. \\n\\nAdditionally, DNA is constantly being used by cells to carry out processes such as protein synthesis, cell division, and repair. Having DNA in every cell allows for the coordination of these processes and ensures that the organism functions properly as a whole. \\n\\nIn summary, every cell in our body contains DNA because it is essential for the proper functioning and development of all living organisms.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "chain.run(\"Why does every cell in our body contain DNA?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
      "metadata": {
        "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e"
      },
      "source": [
        "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "physics_template = \"\"\"You are a very smart physics professor. \\\n",
        "You are great at answering questions about physics in a concise\\\n",
        "and easy to understand manner. \\\n",
        "When you don't know the answer to a question you admit\\\n",
        "that you don't know.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "math_template = \"\"\"You are a very good mathematician. \\\n",
        "You are great at answering math questions. \\\n",
        "You are so good because you are able to break down \\\n",
        "hard problems into their component parts,\n",
        "answer the component parts, and then put them together\\\n",
        "to answer the broader question.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "history_template = \"\"\"You are a very good historian. \\\n",
        "You have an excellent knowledge of and understanding of people,\\\n",
        "events and contexts from a range of historical periods. \\\n",
        "You have the ability to think, reflect, debate, discuss and \\\n",
        "evaluate the past. You have a respect for historical evidence\\\n",
        "and the ability to make use of it to support your explanations \\\n",
        "and judgements.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "\n",
        "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
        "You have a passion for creativity, collaboration,\\\n",
        "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
        "understanding of theories and algorithms, and excellent communication \\\n",
        "skills. You are great at answering coding questions. \\\n",
        "You are so good because you know how to solve a problem by \\\n",
        "describing the solution in imperative steps \\\n",
        "that a machine can easily interpret and you know how to \\\n",
        "choose a solution that has a good balance between \\\n",
        "time complexity and space complexity.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "biology_template = \"\"\"You are an excellent biologist. \\\n",
        "You have a deep understanding of living organisms, \\\n",
        "from the molecular and cellular level to entire ecosystems. \\\n",
        "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
        "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
        "You can clearly communicate how life functions and adapts, \\\n",
        "and you make connections between different biological concepts \\\n",
        "to answer challenging questions.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\"\n",
        "\n",
        "chemistry_template = \"\"\"You are an excellent chemist. \\\n",
        "You have a deep understanding of elements and substances, \\\n",
        "on atmoic level. \\\n",
        "You are skilled at observing patterns in nature, analyzing chemical formulas, \\\n",
        "and explaining complex processes and chemical reactions clearly. \\\n",
        "You can clearly answer challenging questions.\n",
        "\n",
        "Here is a question:\n",
        "{input}\"\"\""
      ],
      "metadata": {
        "id": "sQWX0-r0Vs3U"
      },
      "id": "sQWX0-r0Vs3U",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"physics\",\n",
        "        \"description\": \"Good for answering questions about physics\",\n",
        "        \"prompt_template\": physics_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"math\",\n",
        "        \"description\": \"Good for answering math questions\",\n",
        "        \"prompt_template\": math_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"History\",\n",
        "        \"description\": \"Good for answering history questions\",\n",
        "        \"prompt_template\": history_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"computer science\",\n",
        "        \"description\": \"Good for answering computer science questions\",\n",
        "        \"prompt_template\": computerscience_template\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"biology\",\n",
        "        \"description\": \"Good for answering biology questions\",\n",
        "        \"prompt_template\": biology_template\n",
        "    },\n",
        "      {\n",
        "        \"name\": \"chemistry\",\n",
        "        \"description\": \"Good for answering chemical questions\",\n",
        "        \"prompt_template\": chemistry_template\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "edBmz9kUVsw9"
      },
      "id": "edBmz9kUVsw9",
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "WDGMogoJVsqk"
      },
      "id": "WDGMogoJVsqk",
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "Yoyfza7gVskl"
      },
      "id": "Yoyfza7gVskl",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt_template = p_info[\"prompt_template\"]\n",
        "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)"
      ],
      "metadata": {
        "id": "Vqlxtg9QVsdr"
      },
      "id": "Vqlxtg9QVsdr",
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
      ],
      "metadata": {
        "id": "UzBM6E8qVsXb"
      },
      "id": "UzBM6E8qVsXb",
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
        "language model select the model prompt best suited for the input. \\\n",
        "You will be given the names of the available prompts and a \\\n",
        "description of what the prompt is best suited for. \\\n",
        "You may also revise the original input if you think that revising\\\n",
        "it will ultimately lead to a better response from the language model.\n",
        "\n",
        "<< FORMATTING >>\n",
        "Return a markdown code snippet with a JSON object formatted to look like:\n",
        "```json\n",
        "{{{{\n",
        "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
        "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
        "}}}}\n",
        "```\n",
        "\n",
        "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
        "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
        "well suited for any of the candidate prompts.\n",
        "REMEMBER: \"next_inputs\" can just be the original input \\\n",
        "if you don't think any modifications are needed.\n",
        "\n",
        "<< CANDIDATE PROMPTS >>\n",
        "{destinations}\n",
        "\n",
        "<< INPUT >>\n",
        "{{input}}\n",
        "\n",
        "<< OUTPUT (remember to include the ```json)>>\"\"\""
      ],
      "metadata": {
        "id": "UdFTbleNVsQw"
      },
      "id": "UdFTbleNVsQw",
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations=destinations_str\n",
        ")\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ],
      "metadata": {
        "id": "Zu4rfSQGVsKa"
      },
      "id": "Zu4rfSQGVsKa",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = MultiPromptChain(router_chain=router_chain,\n",
        "                         destination_chains=destination_chains,\n",
        "                         default_chain=default_chain, verbose=True\n",
        "                        )"
      ],
      "metadata": {
        "id": "T--YzljSVsDv"
      },
      "id": "T--YzljSVsDv",
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"At what temperature water changes it's state?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "5urFAsfoVr71",
        "outputId": "1e06d1cf-5e94-42fa-9d3d-c69b08662573"
      },
      "id": "5urFAsfoVr71",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "physics: {'input': 'At what temperature does water change its state?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Water changes its state from a liquid to a solid at 0 degrees Celsius (32 degrees Fahrenheit) and from a liquid to a gas at 100 degrees Celsius (212 degrees Fahrenheit) at standard atmospheric pressure.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"what is the square root of 16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "iCpUhPxkVrzW",
        "outputId": "228ef5d5-0e6e-4db7-d0cc-dee020f3e8a7"
      },
      "id": "iCpUhPxkVrzW",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "math: {'input': 'what is the square root of 16'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The square root of 16 is 4.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"What is object oriented programming?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "rJ286CP8VrqX",
        "outputId": "ec924514-5604-473f-b979-e434d3277e59"
      },
      "id": "rJ286CP8VrqX",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "computer science: {'input': 'What is object oriented programming?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Object-oriented programming (OOP) is a programming paradigm that is based on the concept of \"objects\", which can contain data in the form of fields (attributes or properties) and code in the form of procedures (methods or functions). \\n\\nIn OOP, objects are instances of classes, which define the structure and behavior of the objects. Classes can inherit attributes and methods from other classes, allowing for code reuse and creating a hierarchy of classes. \\n\\nOOP also emphasizes encapsulation, which means that the internal state of an object is hidden from the outside world and can only be accessed through well-defined interfaces. This helps to prevent unintended changes to the object\\'s state and promotes modularity and code reusability. \\n\\nAnother key concept in OOP is polymorphism, which allows objects of different classes to be treated as objects of a common superclass. This enables code to be written in a more generic and flexible way, making it easier to extend and maintain. \\n\\nOverall, OOP provides a powerful and flexible way to model real-world entities and relationships in software, making it a popular choice for developing complex and scalable applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"What are possible ingredients of purfumes?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "ofUt3qaYXa_2",
        "outputId": "7a4c75fd-f376-48f8-a2a5-78da71afcadd"
      },
      "id": "ofUt3qaYXa_2",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
            "chemistry: {'input': 'What are possible ingredients of perfumes?'}\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Perfumes are complex mixtures of various ingredients, including:\\n\\n1. Essential oils: These are natural oils extracted from plants, flowers, fruits, and other botanical sources. They provide the fragrance and aroma of the perfume.\\n\\n2. Aromatic compounds: These are synthetic chemicals that mimic the scents of natural ingredients. They are often used to enhance and stabilize the fragrance of the perfume.\\n\\n3. Solvents: These are liquids that help dissolve and dilute the essential oils and aromatic compounds. Common solvents used in perfumes include alcohol, water, and oils.\\n\\n4. Fixatives: These are substances that help prolong the scent of the perfume on the skin. They help the fragrance last longer and remain stable. Common fixatives include resins, musk, and synthetic chemicals.\\n\\n5. Diluents: These are additional ingredients used to adjust the strength and intensity of the perfume. They help balance the fragrance and ensure it is not too overpowering.\\n\\nOverall, perfumes are a combination of various ingredients that work together to create a unique and appealing scent.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}